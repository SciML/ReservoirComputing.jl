<!DOCTYPE html>
<html lang="en"><head><meta charset="UTF-8"/><meta name="viewport" content="width=device-width, initial-scale=1.0"/><title>Training Reservoir Computing Models · ReservoirComputing.jl</title><meta name="title" content="Training Reservoir Computing Models · ReservoirComputing.jl"/><meta property="og:title" content="Training Reservoir Computing Models · ReservoirComputing.jl"/><meta property="twitter:title" content="Training Reservoir Computing Models · ReservoirComputing.jl"/><meta name="description" content="Documentation for ReservoirComputing.jl."/><meta property="og:description" content="Documentation for ReservoirComputing.jl."/><meta property="twitter:description" content="Documentation for ReservoirComputing.jl."/><meta property="og:url" content="https://docs.sciml.ai/ReservoirComputing/stable/tutorials/train/"/><meta property="twitter:url" content="https://docs.sciml.ai/ReservoirComputing/stable/tutorials/train/"/><link rel="canonical" href="https://docs.sciml.ai/ReservoirComputing/stable/tutorials/train/"/><script data-outdated-warner src="../../assets/warner.js"></script><link href="https://cdnjs.cloudflare.com/ajax/libs/lato-font/3.0.0/css/lato-font.min.css" rel="stylesheet" type="text/css"/><link href="https://cdnjs.cloudflare.com/ajax/libs/juliamono/0.050/juliamono.min.css" rel="stylesheet" type="text/css"/><link href="https://cdnjs.cloudflare.com/ajax/libs/font-awesome/6.4.2/css/fontawesome.min.css" rel="stylesheet" type="text/css"/><link href="https://cdnjs.cloudflare.com/ajax/libs/font-awesome/6.4.2/css/solid.min.css" rel="stylesheet" type="text/css"/><link href="https://cdnjs.cloudflare.com/ajax/libs/font-awesome/6.4.2/css/brands.min.css" rel="stylesheet" type="text/css"/><link href="https://cdnjs.cloudflare.com/ajax/libs/KaTeX/0.16.8/katex.min.css" rel="stylesheet" type="text/css"/><script>documenterBaseURL="../.."</script><script src="https://cdnjs.cloudflare.com/ajax/libs/require.js/2.3.6/require.min.js" data-main="../../assets/documenter.js"></script><script src="../../search_index.js"></script><script src="../../siteinfo.js"></script><script src="../../../versions.js"></script><link class="docs-theme-link" rel="stylesheet" type="text/css" href="../../assets/themes/catppuccin-mocha.css" data-theme-name="catppuccin-mocha"/><link class="docs-theme-link" rel="stylesheet" type="text/css" href="../../assets/themes/catppuccin-macchiato.css" data-theme-name="catppuccin-macchiato"/><link class="docs-theme-link" rel="stylesheet" type="text/css" href="../../assets/themes/catppuccin-frappe.css" data-theme-name="catppuccin-frappe"/><link class="docs-theme-link" rel="stylesheet" type="text/css" href="../../assets/themes/catppuccin-latte.css" data-theme-name="catppuccin-latte"/><link class="docs-theme-link" rel="stylesheet" type="text/css" href="../../assets/themes/documenter-dark.css" data-theme-name="documenter-dark" data-theme-primary-dark/><link class="docs-theme-link" rel="stylesheet" type="text/css" href="../../assets/themes/documenter-light.css" data-theme-name="documenter-light" data-theme-primary/><script src="../../assets/themeswap.js"></script><link href="../../assets/favicon.ico" rel="icon" type="image/x-icon"/></head><body><div id="documenter"><nav class="docs-sidebar"><a class="docs-logo" href="../../"><img src="../../assets/logo.png" alt="ReservoirComputing.jl logo"/></a><div class="docs-package-name"><span class="docs-autofit"><a href="../../">ReservoirComputing.jl</a></span></div><button class="docs-search-query input is-rounded is-small is-clickable my-2 mx-auto py-1 px-2" id="documenter-search-query">Search docs (Ctrl + /)</button><ul class="docs-menu"><li><a class="tocitem" href="../../">ReservoirComputing.jl</a></li><li><a class="tocitem" href="../getting_started/">Getting Started with ReservoirComputing.jl</a></li><li><span class="tocitem">Tutorials</span><ul><li><a class="tocitem" href="../scratch/">Building a model from scratch</a></li><li><a class="tocitem" href="../lorenz_basic/">Chaos forecasting with an ESN</a></li><li><a class="tocitem" href="../ngrc/">Fitting a Next Generation Reservoir Computer</a></li><li><a class="tocitem" href="../deep_esn/">Deep Echo State Networks</a></li><li class="is-active"><a class="tocitem" href>Training Reservoir Computing Models</a><ul class="internal"><li><a class="tocitem" href="#Training-in-ReservoirComputing.jl:-Ridge-Regression"><span>Training in ReservoirComputing.jl: Ridge Regression</span></a></li><li><a class="tocitem" href="#Changing-Ridge-Regression-Solver"><span>Changing Ridge Regression Solver</span></a></li><li><a class="tocitem" href="#Changing-Linear-Regression-Problem"><span>Changing Linear Regression Problem</span></a></li><li><a class="tocitem" href="#Support-Vector-Regression"><span>Support Vector Regression</span></a></li></ul></li><li><a class="tocitem" href="../reca/">Reservoir Computing with Cellular Automata</a></li><li><a class="tocitem" href="../saveload/">Saving and loading models</a></li></ul></li><li><span class="tocitem">Examples</span><ul><li><a class="tocitem" href="../../examples/model_es2n/">Building a model to add to ReservoirComputing.jl</a></li></ul></li><li><span class="tocitem">API Documentation</span><ul><li><a class="tocitem" href="../../api/layers/">Layers</a></li><li><a class="tocitem" href="../../api/models/">Models</a></li><li><a class="tocitem" href="../../api/utils/">Utilities</a></li><li><a class="tocitem" href="../../api/train/">Train</a></li><li><a class="tocitem" href="../../api/predict/">Predict</a></li><li><a class="tocitem" href="../../api/states/">States</a></li><li><a class="tocitem" href="../../api/inits/">Initializers</a></li></ul></li><li><a class="tocitem" href="../../references/">References</a></li></ul><div class="docs-version-selector field has-addons"><div class="control"><span class="docs-label button is-static is-size-7">Version</span></div><div class="docs-selector control is-expanded"><div class="select is-fullwidth is-size-7"><select id="documenter-version-selector"></select></div></div></div></nav><div class="docs-main"><header class="docs-navbar"><a class="docs-sidebar-button docs-navbar-link fa-solid fa-bars is-hidden-desktop" id="documenter-sidebar-button" href="#"></a><nav class="breadcrumb"><ul class="is-hidden-mobile"><li><a class="is-disabled">Tutorials</a></li><li class="is-active"><a href>Training Reservoir Computing Models</a></li></ul><ul class="is-hidden-tablet"><li class="is-active"><a href>Training Reservoir Computing Models</a></li></ul></nav><div class="docs-right"><a class="docs-navbar-link" href="https://github.com/SciML/ReservoirComputing.jl" title="View the repository on GitHub"><span class="docs-icon fa-brands"></span><span class="docs-label is-hidden-touch">GitHub</span></a><a class="docs-navbar-link" href="https://github.com/SciML/ReservoirComputing.jl/blob/master/docs/src/tutorials/train.md" title="Edit source on GitHub"><span class="docs-icon fa-solid"></span></a><a class="docs-settings-button docs-navbar-link fa-solid fa-gear" id="documenter-settings-button" href="#" title="Settings"></a><a class="docs-article-toggle-button fa-solid fa-chevron-up" id="documenter-article-toggle-button" href="javascript:;" title="Collapse all docstrings"></a></div></header><article class="content" id="documenter-page"><h1 id="Training-Reservoir-Computing-Models"><a class="docs-heading-anchor" href="#Training-Reservoir-Computing-Models">Training Reservoir Computing Models</a><a id="Training-Reservoir-Computing-Models-1"></a><a class="docs-heading-anchor-permalink" href="#Training-Reservoir-Computing-Models" title="Permalink"></a></h1><p>Training reservoir computing (RC) models usually means solving a linear regression problem. ReservoirComputing.jl offers multiple stratedies to provide a readout; in this page we will show the basics, while also pointing out the possible extensions.</p><h2 id="Training-in-ReservoirComputing.jl:-Ridge-Regression"><a class="docs-heading-anchor" href="#Training-in-ReservoirComputing.jl:-Ridge-Regression">Training in ReservoirComputing.jl: Ridge Regression</a><a id="Training-in-ReservoirComputing.jl:-Ridge-Regression-1"></a><a class="docs-heading-anchor-permalink" href="#Training-in-ReservoirComputing.jl:-Ridge-Regression" title="Permalink"></a></h2><p>The most simple training of RC models is through ridge regression. Given the widepread adoption of this training mechanism, ridge regression is the default training algorithm for RC models in the library.</p><pre><code class="language-julia hljs">using ReservoirComputing
using Random
Random.seed!(42)
rng = MersenneTwister(42)

input_data = rand(Float32, 3, 100)
target_data = rand(Float32, 5, 100)

model = ESN(3, 100, 5)
ps, st = setup(rng, model)
ps, st = train!(model, input_data, target_data, ps, st,
    StandardRidge(); # default
    solver = QRSolver()) # default</code></pre><pre class="documenter-example-output"><code class="nohighlight hljs ansi">((reservoir = (input_matrix = Float32[0.086408615 0.0998888 -0.013271046; -0.06170206 -0.06359978 0.0921186; … ; -0.027093245 -0.04336114 -0.04771917; 0.07098396 0.015740562 0.019439578], reservoir_matrix = Float32[0.0 0.0 … 0.0 0.38458103; 0.0 0.0 … 0.0 0.0; … ; 0.0 0.0 … 0.0 0.0; 0.0 0.07436356 … 0.0 0.0]), states_modifiers = (), readout = (weight = [155.35108756323686 -135.8712657819953 … 155.88074896713223 -17.109907041437385; 269.94220128782416 -308.8849300590367 … 308.3685883855184 -132.17113965976264; … ; 278.4173811801401 -303.6919995502757 … 244.19595651464243 -197.58585602683507; -3.5393982571778024 37.21017225452454 … -1.2648540501081846 31.08003819647461],)), (reservoir = (cell = (rng = Random.MersenneTwister(42, (0, 25050, 24048, 870)),), carry = (Float32[0.14156468; -0.036177248; … ; -0.38727927; 0.09736941;;],)), states_modifiers = (), readout = NamedTuple(), states = Float32[0.67556715 0.16518015 … 0.1620921 0.14156468; 0.0003713667 -0.30405453 … 0.0013688962 -0.036177248; … ; -0.2935047 0.20566761 … -0.345226 -0.38727927; -0.7566881 -0.592658 … 0.047118302 0.09736941]))</code></pre><p>In this call you can see that there are two possible knobs to be modified: the loss function, in this case ridge, and the solver, in this case the build in QR factorization. In the remaining part of this tutorial we will see how it is possible to change either.</p><h2 id="Changing-Ridge-Regression-Solver"><a class="docs-heading-anchor" href="#Changing-Ridge-Regression-Solver">Changing Ridge Regression Solver</a><a id="Changing-Ridge-Regression-Solver-1"></a><a class="docs-heading-anchor-permalink" href="#Changing-Ridge-Regression-Solver" title="Permalink"></a></h2><p>Building on SciML&#39;s <a href="https://github.com/SciML/LinearSolve.jl">LinearSolve.jl</a>, it is possible to leverage multiple solvers for the ridge problem. For instance, building on the previous example:</p><pre><code class="language-julia hljs">using LinearSolve

ps, st = train!(model, input_data, target_data, ps, st,
    StandardRidge(); # default
    solver = SVDFactorization()) # from LinearSolve</code></pre><pre class="documenter-example-output"><code class="nohighlight hljs ansi">((reservoir = (input_matrix = Float32[0.086408615 0.0998888 -0.013271046; -0.06170206 -0.06359978 0.0921186; … ; -0.027093245 -0.04336114 -0.04771917; 0.07098396 0.015740562 0.019439578], reservoir_matrix = Float32[0.0 0.0 … 0.0 0.38458103; 0.0 0.0 … 0.0 0.0; … ; 0.0 0.0 … 0.0 0.0; 0.0 0.07436356 … 0.0 0.0]), states_modifiers = (), readout = (weight = Float32[-0.42554864 2.830525 … -10.93533 9.562259; -1.7472765 11.085349 … -2.2991953 -6.7392015; … ; 0.51117396 16.642477 … 3.350666 1.195735; 4.609715 -1.8165002 … -16.057856 6.02251],)), (reservoir = (cell = (rng = Random.MersenneTwister(42, (0, 25050, 24048, 870)),), carry = (Float32[0.14502607; -0.030527564; … ; -0.38960707; 0.09629541;;],)), states_modifiers = (), readout = NamedTuple(), states = Float32[0.24012297 0.09647721 … 0.15855159 0.14502607; 0.070599996 -0.07172731 … -0.0055311597 -0.030527564; … ; -0.3597568 -0.3799437 … -0.34301454 -0.38960707; 0.038221236 0.031300593 … 0.048109535 0.09629541]))</code></pre><p>or </p><pre><code class="language-julia hljs">ps, st = train!(model, input_data, target_data, ps, st,
    StandardRidge(); # default
    solver = QRFactorization()) # from LinearSolve</code></pre><pre class="documenter-example-output"><code class="nohighlight hljs ansi">((reservoir = (input_matrix = Float32[0.086408615 0.0998888 -0.013271046; -0.06170206 -0.06359978 0.0921186; … ; -0.027093245 -0.04336114 -0.04771917; 0.07098396 0.015740562 0.019439578], reservoir_matrix = Float32[0.0 0.0 … 0.0 0.38458103; 0.0 0.0 … 0.0 0.0; … ; 0.0 0.0 … 0.0 0.0; 0.0 0.07436356 … 0.0 0.0]), states_modifiers = (), readout = (weight = Float32[122.6651 11.0168705 … -262.47482 122.44317; 170.44348 -230.26588 … -110.79341 272.9332; … ; 46.673862 70.66685 … -362.86142 471.12817; -93.76712 82.558914 … 130.86298 -78.306595],)), (reservoir = (cell = (rng = Random.MersenneTwister(42, (0, 25050, 24048, 870)),), carry = (Float32[0.14514889; -0.030315312; … ; -0.38968256; 0.09626353;;],)), states_modifiers = (), readout = NamedTuple(), states = Float32[0.2366648 0.099875934 … 0.15842067 0.14514889; 0.06441728 -0.0663825 … -0.0057809157 -0.030315312; … ; -0.3572218 -0.38247722 … -0.34294105 -0.38968256; 0.039269898 0.030111087 … 0.048138604 0.09626353]))</code></pre><p>For a detailed explanation of the different solvers, as well as a complete list of them, we suggest visiting the appropriate page in LinearSolve&#39;s <a href="https://docs.sciml.ai/LinearSolve/stable/solvers/solvers/">documentation</a></p><h2 id="Changing-Linear-Regression-Problem"><a class="docs-heading-anchor" href="#Changing-Linear-Regression-Problem">Changing Linear Regression Problem</a><a id="Changing-Linear-Regression-Problem-1"></a><a class="docs-heading-anchor-permalink" href="#Changing-Linear-Regression-Problem" title="Permalink"></a></h2><p>Linear regression is a general problem, which can be espressed through multiple different loss functions. While ridge regression is the most common in RC, due to its closed form, there are multiple other available. ReservoirComputing.jl leverages <a href="https://github.com/JuliaAI/MLJLinearModels.jl">MLJLinearModels.jl</a> to access all the methods available from that library.</p><div class="admonition is-category-warn" id="Warn-28c1c1bd153de52b"><header class="admonition-header">Warn<a class="admonition-anchor" href="#Warn-28c1c1bd153de52b" title="Permalink"></a></header><div class="admonition-body"><p>Currently MLJLinearModels.jl only supports <code>Float64</code>. If a certain precision is of the upmost importance to you, please refrain from using this external package</p></div></div><p>The train function can be called as before, only this time you can specify different models and different solvers for the linear regression problem:</p><pre><code class="language-julia hljs">using MLJLinearModels

ps, st = train!(model, input_data, target_data, ps, st,
    LassoRegression(fit_intercept=false); # from MLJLinearModels
    solver = ProxGrad()) # from MLJLinearModels</code></pre><pre class="documenter-example-output"><code class="nohighlight hljs ansi">((reservoir = (input_matrix = Float32[0.086408615 0.0998888 -0.013271046; -0.06170206 -0.06359978 0.0921186; … ; -0.027093245 -0.04336114 -0.04771917; 0.07098396 0.015740562 0.019439578], reservoir_matrix = Float32[0.0 0.0 … 0.0 0.38458103; 0.0 0.0 … 0.0 0.0; … ; 0.0 0.0 … 0.0 0.0; 0.0 0.07436356 … 0.0 0.0]), states_modifiers = (), readout = (weight = Float32[0.0 -0.0 … -0.0 0.0; 0.0 -0.0 … -0.0 0.0; … ; 0.0 -0.0 … -0.0 0.0; 0.0 -0.0 … -0.0 0.0],)), (reservoir = (cell = (rng = Random.MersenneTwister(42, (0, 25050, 24048, 870)),), carry = (Float32[0.1451532; -0.030307855; … ; -0.3896852; 0.09626243;;],)), states_modifiers = (), readout = NamedTuple(), states = Float32[0.23654257 0.09999292 … 0.15841615 0.1451532; 0.06419469 -0.066186875 … -0.0057896706 -0.030307855; … ; -0.35713658 -0.3825614 … -0.34293845 -0.3896852; 0.039303705 0.030072607 … 0.048139594 0.09626243]))</code></pre><p>Make sure to check the MLJLinearModels documentation pages for the available <a href="https://juliaai.github.io/MLJLinearModels.jl/stable/models/">models</a> and <a href="https://juliaai.github.io/MLJLinearModels.jl/stable/solvers/">solvers</a>. Please note that not all solvers can be used on all the models. </p><div class="admonition is-info" id="Note-ed342c698ca08f75"><header class="admonition-header">Note<a class="admonition-anchor" href="#Note-ed342c698ca08f75" title="Permalink"></a></header><div class="admonition-body"><p>Currently the support for MLJLinearModels.jl is limited to regressors with <code>fit_intercept=false</code>. We are working on a solution, but until then you will always need to specify it on the regressor.</p></div></div><h2 id="Support-Vector-Regression"><a class="docs-heading-anchor" href="#Support-Vector-Regression">Support Vector Regression</a><a id="Support-Vector-Regression-1"></a><a class="docs-heading-anchor-permalink" href="#Support-Vector-Regression" title="Permalink"></a></h2><p>ReservoirComputing.jl also allows users to train RC models with support vector regression through <a href="https://github.com/JuliaML/LIBSVM.jl">LIBSVM.jl</a>. However, the majority of builtin models in the library uses a <a href="../../api/layers/#ReservoirComputing.LinearReadout"><code>LinearReadout</code></a> by default, which can only be trained with linear regression. In  order to use support vector regression, one needs to build a model with <a href="../../api/layers/#ReservoirComputing.SVMReadout"><code>SVMReadout</code></a></p><pre><code class="language-julia hljs">using LIBSVM

model = ReservoirComputer(
    StatefulLayer(ESNCell(3=&gt;100)),
    SVMReadout(100=&gt;5)
)

ps, st = setup(rng, model)</code></pre><pre class="documenter-example-output"><code class="nohighlight hljs ansi">((reservoir = (input_matrix = Float32[0.036005475 -0.07744928 0.00549283; -0.027602648 -0.03803761 0.029640054; … ; 0.020895792 -0.04784565 -0.09396603; -0.05864432 0.05747981 0.08333655], reservoir_matrix = Float32[0.0 0.0 … -0.056890085 0.0; 0.0 0.0 … 0.0 0.0; … ; 0.0 0.0 … 0.0 -0.06416772; 0.0 0.0 … 0.009671479 0.0]), states_modifiers = (), readout = NamedTuple()), (reservoir = (cell = (rng = Random.MersenneTwister(42, (0, 50100, 49098, 357)),), carry = nothing), states_modifiers = (), readout = NamedTuple()))</code></pre><p>We can now train our new <code>model</code> similarly to before:</p><pre><code class="language-julia hljs">ps, st = train!(model, input_data, target_data, ps, st,
    EpsilonSVR() # from LIBSVM
    )</code></pre><pre class="documenter-example-output"><code class="nohighlight hljs ansi">((reservoir = (input_matrix = Float32[0.036005475 -0.07744928 0.00549283; -0.027602648 -0.03803761 0.029640054; … ; 0.020895792 -0.04784565 -0.09396603; -0.05864432 0.05747981 0.08333655], reservoir_matrix = Float32[0.0 0.0 … -0.056890085 0.0; 0.0 0.0 … 0.0 0.0; … ; 0.0 0.0 … 0.0 -0.06416772; 0.0 0.0 … 0.009671479 0.0]), states_modifiers = (), readout = (models = Any[LIBSVM.EpsilonSVR(LIBSVM.Kernel.RadialBasis, 0.01, 0.1, 1.0, 3, 0.0, 0.001, true, false, LIBSVM.SVM{Float64, LIBSVM.Kernel.KERNEL}(LIBSVM.EpsilonSVR, LIBSVM.Kernel.RadialBasis, nothing, 100, 100, 2, Float64[], Int32[], Float64[], Int32[], LIBSVM.SupportVectors{Vector{Float32}, Matrix{Float32}}(0, Int32[], Float32[], Matrix{Float32}(undef, 100, 0), Int32[], LIBSVM.SVMNode[]), 0.0, Matrix{Float64}(undef, 0, 1), Float64[], Float64[], [-0.0036369473622437157], 3, 0.01, 200.0, 0.001, 1.0, 0.5, 0.1, true, false)), LIBSVM.EpsilonSVR(LIBSVM.Kernel.RadialBasis, 0.01, 0.1, 1.0, 3, 0.0, 0.001, true, false, LIBSVM.SVM{Float64, LIBSVM.Kernel.KERNEL}(LIBSVM.EpsilonSVR, LIBSVM.Kernel.RadialBasis, nothing, 100, 100, 2, Float64[], Int32[], Float64[], Int32[], LIBSVM.SupportVectors{Vector{Float32}, Matrix{Float32}}(0, Int32[], Float32[], Matrix{Float32}(undef, 100, 0), Int32[], LIBSVM.SVMNode[]), 0.0, Matrix{Float64}(undef, 0, 1), Float64[], Float64[], [-0.0036369473622437157], 3, 0.01, 200.0, 0.001, 1.0, 0.5, 0.1, true, false)), LIBSVM.EpsilonSVR(LIBSVM.Kernel.RadialBasis, 0.01, 0.1, 1.0, 3, 0.0, 0.001, true, false, LIBSVM.SVM{Float64, LIBSVM.Kernel.KERNEL}(LIBSVM.EpsilonSVR, LIBSVM.Kernel.RadialBasis, nothing, 100, 100, 2, Float64[], Int32[], Float64[], Int32[], LIBSVM.SupportVectors{Vector{Float32}, Matrix{Float32}}(0, Int32[], Float32[], Matrix{Float32}(undef, 100, 0), Int32[], LIBSVM.SVMNode[]), 0.0, Matrix{Float64}(undef, 0, 1), Float64[], Float64[], [-0.0036369473622437157], 3, 0.01, 200.0, 0.001, 1.0, 0.5, 0.1, true, false)), LIBSVM.EpsilonSVR(LIBSVM.Kernel.RadialBasis, 0.01, 0.1, 1.0, 3, 0.0, 0.001, true, false, LIBSVM.SVM{Float64, LIBSVM.Kernel.KERNEL}(LIBSVM.EpsilonSVR, LIBSVM.Kernel.RadialBasis, nothing, 100, 100, 2, Float64[], Int32[], Float64[], Int32[], LIBSVM.SupportVectors{Vector{Float32}, Matrix{Float32}}(0, Int32[], Float32[], Matrix{Float32}(undef, 100, 0), Int32[], LIBSVM.SVMNode[]), 0.0, Matrix{Float64}(undef, 0, 1), Float64[], Float64[], [-0.0036369473622437157], 3, 0.01, 200.0, 0.001, 1.0, 0.5, 0.1, true, false)), LIBSVM.EpsilonSVR(LIBSVM.Kernel.RadialBasis, 0.01, 0.1, 1.0, 3, 0.0, 0.001, true, false, LIBSVM.SVM{Float64, LIBSVM.Kernel.KERNEL}(LIBSVM.EpsilonSVR, LIBSVM.Kernel.RadialBasis, nothing, 100, 100, 2, Float64[], Int32[], Float64[], Int32[], LIBSVM.SupportVectors{Vector{Float32}, Matrix{Float32}}(0, Int32[], Float32[], Matrix{Float32}(undef, 100, 0), Int32[], LIBSVM.SVMNode[]), 0.0, Matrix{Float64}(undef, 0, 1), Float64[], Float64[], [-0.0036369473622437157], 3, 0.01, 200.0, 0.001, 1.0, 0.5, 0.1, true, false))],)), (reservoir = (cell = (rng = Random.MersenneTwister(42, (0, 50100, 49098, 457)),), carry = (Float32[-0.07993154; -0.056282256; … ; -0.2977938; -0.016758788;;],)), states_modifiers = (), readout = NamedTuple(), states = Float32[0.77942973 -0.61240965 … -0.038224187 -0.07993154; -0.87535733 0.0026252489 … 0.07984722 -0.056282256; … ; -0.85399914 -0.89032173 … -0.25453427 -0.2977938; 0.27237374 -0.12041608 … -0.07133142 -0.016758788]))</code></pre></article><nav class="docs-footer"><a class="docs-footer-prevpage" href="../deep_esn/">« Deep Echo State Networks</a><a class="docs-footer-nextpage" href="../reca/">Reservoir Computing with Cellular Automata »</a><div class="flexbox-break"></div><p class="footer-message">Powered by <a href="https://github.com/JuliaDocs/Documenter.jl">Documenter.jl</a> and the <a href="https://julialang.org/">Julia Programming Language</a>.</p></nav></div><div class="modal" id="documenter-settings"><div class="modal-background"></div><div class="modal-card"><header class="modal-card-head"><p class="modal-card-title">Settings</p><button class="delete"></button></header><section class="modal-card-body"><p><label class="label">Theme</label><div class="select"><select id="documenter-themepicker"><option value="auto">Automatic (OS)</option><option value="documenter-light">documenter-light</option><option value="documenter-dark">documenter-dark</option><option value="catppuccin-latte">catppuccin-latte</option><option value="catppuccin-frappe">catppuccin-frappe</option><option value="catppuccin-macchiato">catppuccin-macchiato</option><option value="catppuccin-mocha">catppuccin-mocha</option></select></div></p><hr/><p>This document was generated with <a href="https://github.com/JuliaDocs/Documenter.jl">Documenter.jl</a> version 1.16.1 on <span class="colophon-date" title="Tuesday 10 February 2026 01:55">Tuesday 10 February 2026</span>. Using Julia version 1.12.4.</p></section><footer class="modal-card-foot"></footer></div></div></div></body></html>
