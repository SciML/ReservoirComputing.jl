<!DOCTYPE html>
<html lang="en"><head><meta charset="UTF-8"/><meta name="viewport" content="width=device-width, initial-scale=1.0"/><title>Lorenz System Forecasting · ReservoirComputing.jl</title><meta name="title" content="Lorenz System Forecasting · ReservoirComputing.jl"/><meta property="og:title" content="Lorenz System Forecasting · ReservoirComputing.jl"/><meta property="twitter:title" content="Lorenz System Forecasting · ReservoirComputing.jl"/><meta name="description" content="Documentation for ReservoirComputing.jl."/><meta property="og:description" content="Documentation for ReservoirComputing.jl."/><meta property="twitter:description" content="Documentation for ReservoirComputing.jl."/><meta property="og:url" content="https://docs.sciml.ai/ReservoirComputing/stable/esn_tutorials/lorenz_basic/"/><meta property="twitter:url" content="https://docs.sciml.ai/ReservoirComputing/stable/esn_tutorials/lorenz_basic/"/><link rel="canonical" href="https://docs.sciml.ai/ReservoirComputing/stable/esn_tutorials/lorenz_basic/"/><script data-outdated-warner src="../../assets/warner.js"></script><link href="https://cdnjs.cloudflare.com/ajax/libs/lato-font/3.0.0/css/lato-font.min.css" rel="stylesheet" type="text/css"/><link href="https://cdnjs.cloudflare.com/ajax/libs/juliamono/0.050/juliamono.min.css" rel="stylesheet" type="text/css"/><link href="https://cdnjs.cloudflare.com/ajax/libs/font-awesome/6.4.2/css/fontawesome.min.css" rel="stylesheet" type="text/css"/><link href="https://cdnjs.cloudflare.com/ajax/libs/font-awesome/6.4.2/css/solid.min.css" rel="stylesheet" type="text/css"/><link href="https://cdnjs.cloudflare.com/ajax/libs/font-awesome/6.4.2/css/brands.min.css" rel="stylesheet" type="text/css"/><link href="https://cdnjs.cloudflare.com/ajax/libs/KaTeX/0.16.8/katex.min.css" rel="stylesheet" type="text/css"/><script>documenterBaseURL="../.."</script><script src="https://cdnjs.cloudflare.com/ajax/libs/require.js/2.3.6/require.min.js" data-main="../../assets/documenter.js"></script><script src="../../search_index.js"></script><script src="../../siteinfo.js"></script><script src="../../../versions.js"></script><link class="docs-theme-link" rel="stylesheet" type="text/css" href="../../assets/themes/catppuccin-mocha.css" data-theme-name="catppuccin-mocha"/><link class="docs-theme-link" rel="stylesheet" type="text/css" href="../../assets/themes/catppuccin-macchiato.css" data-theme-name="catppuccin-macchiato"/><link class="docs-theme-link" rel="stylesheet" type="text/css" href="../../assets/themes/catppuccin-frappe.css" data-theme-name="catppuccin-frappe"/><link class="docs-theme-link" rel="stylesheet" type="text/css" href="../../assets/themes/catppuccin-latte.css" data-theme-name="catppuccin-latte"/><link class="docs-theme-link" rel="stylesheet" type="text/css" href="../../assets/themes/documenter-dark.css" data-theme-name="documenter-dark" data-theme-primary-dark/><link class="docs-theme-link" rel="stylesheet" type="text/css" href="../../assets/themes/documenter-light.css" data-theme-name="documenter-light" data-theme-primary/><script src="../../assets/themeswap.js"></script><link href="../../assets/favicon.ico" rel="icon" type="image/x-icon"/></head><body><div id="documenter"><nav class="docs-sidebar"><a class="docs-logo" href="../../"><img src="../../assets/logo.png" alt="ReservoirComputing.jl logo"/></a><div class="docs-package-name"><span class="docs-autofit"><a href="../../">ReservoirComputing.jl</a></span></div><button class="docs-search-query input is-rounded is-small is-clickable my-2 mx-auto py-1 px-2" id="documenter-search-query">Search docs (Ctrl + /)</button><ul class="docs-menu"><li><a class="tocitem" href="../../">ReservoirComputing.jl</a></li><li><span class="tocitem">General Settings</span><ul><li><a class="tocitem" href="../../general/different_training/">Changing Training Algorithms</a></li><li><a class="tocitem" href="../../general/states_variation/">Altering States</a></li><li><a class="tocitem" href="../../general/predictive_generative/">Generative vs Predictive</a></li></ul></li><li><span class="tocitem">Echo State Network Tutorials</span><ul><li class="is-active"><a class="tocitem" href>Lorenz System Forecasting</a><ul class="internal"><li><a class="tocitem" href="#Generating-the-data"><span>Generating the data</span></a></li><li><a class="tocitem" href="#Building-the-Echo-State-Network"><span>Building the Echo State Network</span></a></li><li><a class="tocitem" href="#Training-and-Prediction"><span>Training and Prediction</span></a></li><li><a class="tocitem" href="#Bibliography"><span>Bibliography</span></a></li></ul></li><li><a class="tocitem" href="../change_layers/">Using Different Layers</a></li><li><a class="tocitem" href="../different_drivers/">Using Different Reservoir Drivers</a></li><li><a class="tocitem" href="../deep_esn/">Deep Echo State Networks</a></li><li><a class="tocitem" href="../hybrid/">Hybrid Echo State Networks</a></li></ul></li><li><a class="tocitem" href="../../reca_tutorials/reca/">Reservoir Computing with Cellular Automata</a></li><li><span class="tocitem">API Documentation</span><ul><li><a class="tocitem" href="../../api/training/">Training Algorithms</a></li><li><a class="tocitem" href="../../api/states/">States Modifications</a></li><li><a class="tocitem" href="../../api/predict/">Prediction Types</a></li><li><a class="tocitem" href="../../api/esn/">Echo State Networks</a></li><li><a class="tocitem" href="../../api/inits/">ESN Initializers</a></li><li><a class="tocitem" href="../../api/esn_drivers/">ESN Drivers</a></li><li><a class="tocitem" href="../../api/esn_variations/">ESN Variations</a></li><li><a class="tocitem" href="../../api/reca/">ReCA</a></li></ul></li></ul><div class="docs-version-selector field has-addons"><div class="control"><span class="docs-label button is-static is-size-7">Version</span></div><div class="docs-selector control is-expanded"><div class="select is-fullwidth is-size-7"><select id="documenter-version-selector"></select></div></div></div></nav><div class="docs-main"><header class="docs-navbar"><a class="docs-sidebar-button docs-navbar-link fa-solid fa-bars is-hidden-desktop" id="documenter-sidebar-button" href="#"></a><nav class="breadcrumb"><ul class="is-hidden-mobile"><li><a class="is-disabled">Echo State Network Tutorials</a></li><li class="is-active"><a href>Lorenz System Forecasting</a></li></ul><ul class="is-hidden-tablet"><li class="is-active"><a href>Lorenz System Forecasting</a></li></ul></nav><div class="docs-right"><a class="docs-navbar-link" href="https://github.com/SciML/ReservoirComputing.jl" title="View the repository on GitHub"><span class="docs-icon fa-brands"></span><span class="docs-label is-hidden-touch">GitHub</span></a><a class="docs-navbar-link" href="https://github.com/SciML/ReservoirComputing.jl/blob/master/docs/src/esn_tutorials/lorenz_basic.md" title="Edit source on GitHub"><span class="docs-icon fa-solid"></span></a><a class="docs-settings-button docs-navbar-link fa-solid fa-gear" id="documenter-settings-button" href="#" title="Settings"></a><a class="docs-article-toggle-button fa-solid fa-chevron-up" id="documenter-article-toggle-button" href="javascript:;" title="Collapse all docstrings"></a></div></header><article class="content" id="documenter-page"><h1 id="Lorenz-System-Forecasting"><a class="docs-heading-anchor" href="#Lorenz-System-Forecasting">Lorenz System Forecasting</a><a id="Lorenz-System-Forecasting-1"></a><a class="docs-heading-anchor-permalink" href="#Lorenz-System-Forecasting" title="Permalink"></a></h1><p>This example expands on the readme Lorenz system forecasting to better showcase how to use methods and functions provided in the library for Echo State Networks. Here the prediction method used is <code>Generative</code>, for a more detailed explanation of the differences between <code>Generative</code> and <code>Predictive</code> please refer to the other examples given in the documentation.</p><h2 id="Generating-the-data"><a class="docs-heading-anchor" href="#Generating-the-data">Generating the data</a><a id="Generating-the-data-1"></a><a class="docs-heading-anchor-permalink" href="#Generating-the-data" title="Permalink"></a></h2><p>Starting off the workflow, the first step is to obtain the data. Leveraging <code>OrdinaryDiffEq</code> it is possible to derive the Lorenz system data in the following way:</p><pre><code class="language-julia hljs">using OrdinaryDiffEq

#define lorenz system
function lorenz!(du, u, p, t)
    du[1] = 10.0 * (u[2] - u[1])
    du[2] = u[1] * (28.0 - u[3]) - u[2]
    du[3] = u[1] * u[2] - (8 / 3) * u[3]
end

#solve and take data
prob = ODEProblem(lorenz!, [1.0, 0.0, 0.0], (0.0, 200.0))
data = solve(prob, ABM54(); dt=0.02)
data = reduce(hcat, data.u)</code></pre><pre class="documenter-example-output"><code class="nohighlight hljs ansi">3×10001 Matrix{Float64}:
 1.0  0.868014    0.846922   0.912746   …  -5.41248   -4.48696   -3.72246
 0.0  0.511611    0.972162   1.43659       -0.380216  -0.265298  -0.291495
 0.0  0.00464843  0.0167238  0.0363891     29.841     28.3209    26.8714</code></pre><p>After obtaining the data, it is necessary to determine the kind of prediction for the model. Since this example will use the <code>Generative</code> prediction type, this means that the target data will be the next step of the input data. In addition, it is important to notice that the Lorenz system just obtained presents a transient period that is not representative of the general behavior of the system. This can easily be discarded by setting a <code>shift</code> parameter.</p><pre><code class="language-julia hljs">#determine shift length, training length and prediction length
shift = 300
train_len = 5000
predict_len = 1250

#split the data accordingly
input_data = data[:, shift:(shift + train_len - 1)]
target_data = data[:, (shift + 1):(shift + train_len)]
test_data = data[:, (shift + train_len + 1):(shift + train_len + predict_len)]</code></pre><pre class="documenter-example-output"><code class="nohighlight hljs ansi">3×1250 Matrix{Float64}:
  4.2235    3.83533   3.55846   3.38262  …   9.44212  10.0034  10.5085
  1.98782   2.18137   2.43519   2.7396      12.3382   12.6956  12.8396
 25.6556   24.4858   23.3794   22.3394      24.3255   25.4374  26.6729</code></pre><p>It is <em>important</em> to notice that the data needs to be formatted in a matrix with the features as rows and time steps as columns as in this example. This is needed even if the time series consists of single values.</p><h2 id="Building-the-Echo-State-Network"><a class="docs-heading-anchor" href="#Building-the-Echo-State-Network">Building the Echo State Network</a><a id="Building-the-Echo-State-Network-1"></a><a class="docs-heading-anchor-permalink" href="#Building-the-Echo-State-Network" title="Permalink"></a></h2><p>Once the data is ready, it is possible to define the parameters for the ESN and the <code>ESN</code> struct itself. In this example, the values from <sup class="footnote-reference"><a id="citeref-1" href="#footnote-1">[1]</a></sup> are loosely followed as general guidelines.</p><pre><code class="language-julia hljs">using ReservoirComputing

#define ESN parameters
res_size = 300
in_size = 3
res_radius = 1.2
res_sparsity = 6 / 300
input_scaling = 0.1

#build ESN struct
esn = ESN(input_data, in_size, res_size;
    reservoir=rand_sparse(; radius=res_radius, sparsity=res_sparsity),
    input_layer=weighted_init(; scaling=input_scaling),
    reservoir_driver=RNN(),
    nla_type=NLADefault(),
    states_type=StandardStates())</code></pre><pre class="documenter-example-output"><code class="nohighlight hljs ansi">ESN(3 =&gt; 300)</code></pre><p>Most of the parameters chosen here mirror the default ones, so a direct call is not necessary. The readme example is identical to this one, except for the explicit call. Going line by line to see what is happening, starting from <code>res_size</code>: this value determines the dimensions of the reservoir matrix. In this case, a size of 300 has been chosen, so the reservoir matrix will be 300 x 300. This is not always the case, since some input layer constructions can modify the dimensions of the reservoir, but in that case, everything is taken care of internally.</p><p>The <code>res_radius</code> determines the scaling of the spectral radius of the reservoir matrix; a proper scaling is necessary to assure the Echo State Property. The default value in the <code>rand_sparse</code> method is 1.0 in accordance with the most commonly followed guidelines found in the literature (see <sup class="footnote-reference"><a id="citeref-2" href="#footnote-2">[2]</a></sup> and references therein). The <code>sparsity</code> of the reservoir matrix in this case is obtained by choosing a degree of connections and dividing that by the reservoir size. Of course, it is also possible to simply choose any value between 0.0 and 1.0 to test behaviors for different sparsity values.</p><p>The value of <code>input_scaling</code> determines the upper and lower bounds of the uniform distribution of the weights in the <code>weighted_init</code>. The value of 0.1 represents the default. The default input layer is the <code>scaled_rand</code>, a dense matrix. The details of the weighted version can be found in <sup class="footnote-reference"><a id="citeref-3" href="#footnote-3">[3]</a></sup>, for this example, this version returns the best results.</p><p>The reservoir driver represents the dynamics of the reservoir. In the standard ESN definition, these dynamics are obtained through a Recurrent Neural Network (RNN), and this is reflected by calling the <code>RNN</code> driver for the <code>ESN</code> struct. This option is set as the default, and unless there is the need to change parameters, it is not needed. The full equation is the following:</p><p class="math-container">\[\textbf{x}(t+1) = (1-\alpha)\textbf{x}(t) + \alpha \cdot \text{tanh}(\textbf{W}\textbf{x}(t)+\textbf{W}_{\text{in}}\textbf{u}(t))\]</p><p>where <span>$α$</span> represents the leaky coefficient, and tanh can be any activation function. Also, <span>$\textbf{x}$</span> represents the state vector, <span>$\textbf{u}$</span> the input data, and <span>$\textbf{W}, \textbf{W}_{\text{in}}$</span> are the reservoir matrix and input matrix, respectively. The default call to the RNN in the library is the following <code>RNN(;activation_function=tanh, leaky_coefficient=1.0)</code>, where the meaning of the parameters is clear from the equation above. Instead of the hyperbolic tangent, any activation function can be used, either leveraging external libraries such as <code>NNlib</code> or creating a custom one.</p><p>The final calls are modifications to the states in training or prediction. The default calls, depicted in the example, do not make any modifications to the states. This is the safest bet if one is not sure how these work. The <code>nla_type</code> applies a non-linear algorithm to the states, while the <code>states_type</code> can expand them by concatenating them with the input data, or padding them by concatenating a constant value to all the states. More in depth descriptions of these parameters are given in other examples in the documentation.</p><h2 id="Training-and-Prediction"><a class="docs-heading-anchor" href="#Training-and-Prediction">Training and Prediction</a><a id="Training-and-Prediction-1"></a><a class="docs-heading-anchor-permalink" href="#Training-and-Prediction" title="Permalink"></a></h2><p>Now that the ESN has been created and all the parameters have been explained, it is time to proceed with the training. The full call of the readme example follows this general idea:</p><pre><code class="language-julia hljs">#define training method
training_method = StandardRidge(0.0)

#obtain output layer
output_layer = train(esn, target_data, training_method)</code></pre><pre class="documenter-example-output"><code class="nohighlight hljs ansi">OutputLayer successfully trained with output size: 3</code></pre><p>The training returns an <code>OutputLayer</code> struct containing the trained output matrix and other  needed for the prediction. The necessary elements in the <code>train()</code> call are the <code>ESN</code> struct created in the previous step and the <code>target_data</code>, which in this case is the one step ahead evolution of the Lorenz system. The training method chosen in this example is the standard one, so an equivalent way of calling the <code>train</code> function here is <code>output_layer = train(esn, target_data)</code> like the readme basic version. Likewise, the default value for the ridge regression parameter is set to zero, so the actual default training is Ordinary Least Squares regression. Other training methods are available and will be explained in the following examples.</p><p>Once the <code>OutputLayer</code> has been obtained, the prediction can be done following this procedure:</p><pre><code class="language-julia hljs">output = esn(Generative(predict_len), output_layer)</code></pre><pre class="documenter-example-output"><code class="nohighlight hljs ansi">3×1250 Matrix{Float64}:
  4.22376   3.83589   3.55846   3.38306  …  -1.03032  -1.41547  -1.75278
  1.98878   2.18157   2.43625   2.73974     -3.10842  -3.19682  -3.36996
 25.6609   24.4894   23.394    22.359       22.2097   21.1379   20.1301</code></pre><p>both the training method and the output layer are needed in this call. The number of steps for the prediction must be specified in the <code>Generative</code> method. The output results are given in a matrix.</p><div class="admonition is-info"><header class="admonition-header">Saving the states during prediction</header><div class="admonition-body"><p>While the states are saved in the <code>ESN</code> struct for the training, for the prediction they are not saved by default. To inspect the states, it is necessary to pass the boolean keyword argument <code>save_states</code> to the prediction call, in this example using <code>esn(... ; save_states=true)</code>. This returns a tuple <code>(output, states)</code> where <code>size(states) = res_size, prediction_len</code></p></div></div><p>To inspect the results, they can easily be plotted using an external library. In this case, <code>Plots</code> is adopted:</p><pre><code class="language-julia hljs">using Plots, Plots.PlotMeasures

ts = 0.0:0.02:200.0
lorenz_maxlyap = 0.9056
predict_ts = ts[(shift + train_len + 1):(shift + train_len + predict_len)]
lyap_time = (predict_ts .- predict_ts[1]) * (1 / lorenz_maxlyap)

p1 = plot(lyap_time, [test_data[1, :] output[1, :]]; label=[&quot;actual&quot; &quot;predicted&quot;],
    ylabel=&quot;x(t)&quot;, linewidth=2.5, xticks=false, yticks=-15:15:15);
p2 = plot(lyap_time, [test_data[2, :] output[2, :]]; label=[&quot;actual&quot; &quot;predicted&quot;],
    ylabel=&quot;y(t)&quot;, linewidth=2.5, xticks=false, yticks=-20:20:20);
p3 = plot(lyap_time, [test_data[3, :] output[3, :]]; label=[&quot;actual&quot; &quot;predicted&quot;],
    ylabel=&quot;z(t)&quot;, linewidth=2.5, xlabel=&quot;max(λ)*t&quot;, yticks=10:15:40);

plot(p1, p2, p3; plot_title=&quot;Lorenz System Coordinates&quot;,
    layout=(3, 1), xtickfontsize=12, ytickfontsize=12, xguidefontsize=15,
    yguidefontsize=15,
    legendfontsize=12, titlefontsize=20)</code></pre><img src="b92472a6.svg" alt="Example block output"/><h2 id="Bibliography"><a class="docs-heading-anchor" href="#Bibliography">Bibliography</a><a id="Bibliography-1"></a><a class="docs-heading-anchor-permalink" href="#Bibliography" title="Permalink"></a></h2><section class="footnotes is-size-7"><ul><li class="footnote" id="footnote-1"><a class="tag is-link" href="#citeref-1">1</a>Pathak, Jaideep, et al. &quot;<em>Using machine learning to replicate chaotic attractors and calculate Lyapunov exponents from data.</em>&quot; Chaos: An Interdisciplinary Journal of Nonlinear Science 27.12 (2017): 121102.</li><li class="footnote" id="footnote-2"><a class="tag is-link" href="#citeref-2">2</a>Lukoševičius, Mantas. &quot;<em>A practical guide to applying echo state networks.</em>&quot; Neural networks: Tricks of the trade. Springer, Berlin, Heidelberg, 2012. 659-686.</li><li class="footnote" id="footnote-3"><a class="tag is-link" href="#citeref-3">3</a>Lu, Zhixin, et al. &quot;<em>Reservoir observers: Model-free inference of unmeasured variables in chaotic systems.</em>&quot; Chaos: An Interdisciplinary Journal of Nonlinear Science 27.4 (2017): 041102.</li></ul></section></article><nav class="docs-footer"><a class="docs-footer-prevpage" href="../../general/predictive_generative/">« Generative vs Predictive</a><a class="docs-footer-nextpage" href="../change_layers/">Using Different Layers »</a><div class="flexbox-break"></div><p class="footer-message">Powered by <a href="https://github.com/JuliaDocs/Documenter.jl">Documenter.jl</a> and the <a href="https://julialang.org/">Julia Programming Language</a>.</p></nav></div><div class="modal" id="documenter-settings"><div class="modal-background"></div><div class="modal-card"><header class="modal-card-head"><p class="modal-card-title">Settings</p><button class="delete"></button></header><section class="modal-card-body"><p><label class="label">Theme</label><div class="select"><select id="documenter-themepicker"><option value="auto">Automatic (OS)</option><option value="documenter-light">documenter-light</option><option value="documenter-dark">documenter-dark</option><option value="catppuccin-latte">catppuccin-latte</option><option value="catppuccin-frappe">catppuccin-frappe</option><option value="catppuccin-macchiato">catppuccin-macchiato</option><option value="catppuccin-mocha">catppuccin-mocha</option></select></div></p><hr/><p>This document was generated with <a href="https://github.com/JuliaDocs/Documenter.jl">Documenter.jl</a> version 1.8.0 on <span class="colophon-date" title="Thursday 6 February 2025 10:23">Thursday 6 February 2025</span>. Using Julia version 1.11.3.</p></section><footer class="modal-card-foot"></footer></div></div></div></body></html>
