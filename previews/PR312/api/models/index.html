<!DOCTYPE html>
<html lang="en"><head><meta charset="UTF-8"/><meta name="viewport" content="width=device-width, initial-scale=1.0"/><title>Models · ReservoirComputing.jl</title><meta name="title" content="Models · ReservoirComputing.jl"/><meta property="og:title" content="Models · ReservoirComputing.jl"/><meta property="twitter:title" content="Models · ReservoirComputing.jl"/><meta name="description" content="Documentation for ReservoirComputing.jl."/><meta property="og:description" content="Documentation for ReservoirComputing.jl."/><meta property="twitter:description" content="Documentation for ReservoirComputing.jl."/><meta property="og:url" content="https://docs.sciml.ai/ReservoirComputing/stable/api/models/"/><meta property="twitter:url" content="https://docs.sciml.ai/ReservoirComputing/stable/api/models/"/><link rel="canonical" href="https://docs.sciml.ai/ReservoirComputing/stable/api/models/"/><script data-outdated-warner src="../../assets/warner.js"></script><link href="https://cdnjs.cloudflare.com/ajax/libs/lato-font/3.0.0/css/lato-font.min.css" rel="stylesheet" type="text/css"/><link href="https://cdnjs.cloudflare.com/ajax/libs/juliamono/0.050/juliamono.min.css" rel="stylesheet" type="text/css"/><link href="https://cdnjs.cloudflare.com/ajax/libs/font-awesome/6.4.2/css/fontawesome.min.css" rel="stylesheet" type="text/css"/><link href="https://cdnjs.cloudflare.com/ajax/libs/font-awesome/6.4.2/css/solid.min.css" rel="stylesheet" type="text/css"/><link href="https://cdnjs.cloudflare.com/ajax/libs/font-awesome/6.4.2/css/brands.min.css" rel="stylesheet" type="text/css"/><link href="https://cdnjs.cloudflare.com/ajax/libs/KaTeX/0.16.8/katex.min.css" rel="stylesheet" type="text/css"/><script>documenterBaseURL="../.."</script><script src="https://cdnjs.cloudflare.com/ajax/libs/require.js/2.3.6/require.min.js" data-main="../../assets/documenter.js"></script><script src="../../search_index.js"></script><script src="../../siteinfo.js"></script><script src="../../../versions.js"></script><link class="docs-theme-link" rel="stylesheet" type="text/css" href="../../assets/themes/catppuccin-mocha.css" data-theme-name="catppuccin-mocha"/><link class="docs-theme-link" rel="stylesheet" type="text/css" href="../../assets/themes/catppuccin-macchiato.css" data-theme-name="catppuccin-macchiato"/><link class="docs-theme-link" rel="stylesheet" type="text/css" href="../../assets/themes/catppuccin-frappe.css" data-theme-name="catppuccin-frappe"/><link class="docs-theme-link" rel="stylesheet" type="text/css" href="../../assets/themes/catppuccin-latte.css" data-theme-name="catppuccin-latte"/><link class="docs-theme-link" rel="stylesheet" type="text/css" href="../../assets/themes/documenter-dark.css" data-theme-name="documenter-dark" data-theme-primary-dark/><link class="docs-theme-link" rel="stylesheet" type="text/css" href="../../assets/themes/documenter-light.css" data-theme-name="documenter-light" data-theme-primary/><script src="../../assets/themeswap.js"></script><link href="../../assets/favicon.ico" rel="icon" type="image/x-icon"/></head><body><div id="documenter"><nav class="docs-sidebar"><a class="docs-logo" href="../../"><img src="../../assets/logo.png" alt="ReservoirComputing.jl logo"/></a><div class="docs-package-name"><span class="docs-autofit"><a href="../../">ReservoirComputing.jl</a></span></div><button class="docs-search-query input is-rounded is-small is-clickable my-2 mx-auto py-1 px-2" id="documenter-search-query">Search docs (Ctrl + /)</button><ul class="docs-menu"><li><a class="tocitem" href="../../">ReservoirComputing.jl</a></li><li><span class="tocitem">Tutorials</span><ul><li><a class="tocitem" href="../../tutorials/scratch/">Building a model from scratch</a></li><li><a class="tocitem" href="../../tutorials/lorenz_basic/">Chaos forecasting with an ESN</a></li><li><a class="tocitem" href="../../tutorials/deep_esn/">Deep Echo State Networks</a></li><li><a class="tocitem" href="../../tutorials/reca/">Reservoir Computing with Cellular Automata</a></li></ul></li><li><span class="tocitem">API Documentation</span><ul><li><a class="tocitem" href="../layers/">Layers</a></li><li class="is-active"><a class="tocitem" href>Models</a><ul class="internal"><li><a class="tocitem" href="#Echo-State-Networks"><span>Echo State Networks</span></a></li><li><a class="tocitem" href="#Reservoir-Computing-with-Cellular-Automata"><span>Reservoir Computing with Cellular Automata</span></a></li></ul></li><li><a class="tocitem" href="../utils/">Utilities</a></li><li><a class="tocitem" href="../train/">Train</a></li><li><a class="tocitem" href="../predict/">Predict</a></li><li><a class="tocitem" href="../states/">States</a></li><li><a class="tocitem" href="../inits/">Initializers</a></li></ul></li><li><a class="tocitem" href="../../references/">References</a></li></ul><div class="docs-version-selector field has-addons"><div class="control"><span class="docs-label button is-static is-size-7">Version</span></div><div class="docs-selector control is-expanded"><div class="select is-fullwidth is-size-7"><select id="documenter-version-selector"></select></div></div></div></nav><div class="docs-main"><header class="docs-navbar"><a class="docs-sidebar-button docs-navbar-link fa-solid fa-bars is-hidden-desktop" id="documenter-sidebar-button" href="#"></a><nav class="breadcrumb"><ul class="is-hidden-mobile"><li><a class="is-disabled">API Documentation</a></li><li class="is-active"><a href>Models</a></li></ul><ul class="is-hidden-tablet"><li class="is-active"><a href>Models</a></li></ul></nav><div class="docs-right"><a class="docs-navbar-link" href="https://github.com/SciML/ReservoirComputing.jl" title="View the repository on GitHub"><span class="docs-icon fa-brands"></span><span class="docs-label is-hidden-touch">GitHub</span></a><a class="docs-navbar-link" href="https://github.com/SciML/ReservoirComputing.jl/blob/master/docs/src/api/models.md" title="Edit source on GitHub"><span class="docs-icon fa-solid"></span></a><a class="docs-settings-button docs-navbar-link fa-solid fa-gear" id="documenter-settings-button" href="#" title="Settings"></a><a class="docs-article-toggle-button fa-solid fa-chevron-up" id="documenter-article-toggle-button" href="javascript:;" title="Collapse all docstrings"></a></div></header><article class="content" id="documenter-page"><h1 id="Models"><a class="docs-heading-anchor" href="#Models">Models</a><a id="Models-1"></a><a class="docs-heading-anchor-permalink" href="#Models" title="Permalink"></a></h1><h2 id="Echo-State-Networks"><a class="docs-heading-anchor" href="#Echo-State-Networks">Echo State Networks</a><a id="Echo-State-Networks-1"></a><a class="docs-heading-anchor-permalink" href="#Echo-State-Networks" title="Permalink"></a></h2><article><details class="docstring" open="true"><summary id="ReservoirComputing.ESN"><a class="docstring-binding" href="#ReservoirComputing.ESN"><code>ReservoirComputing.ESN</code></a> — <span class="docstring-category">Function</span></summary><section><div><pre><code class="language-julia hljs">ESN(in_dims, res_dims, out_dims, activation=tanh;
    leak_coefficient=1.0, init_reservoir=rand_sparse, init_input=scaled_rand,
    init_bias=zeros32, init_state=randn32, use_bias=false,
    state_modifiers=(), readout_activation=identity)</code></pre><p>Echo State Network (ESN): a reservoir (recurrent) layer followed by an optional sequence of state-modifier layers and a linear readout.</p><p><code>ESN</code> composes:</p><ol><li>a stateful <a href="../layers/#ReservoirComputing.ESNCell"><code>ESNCell</code></a> (reservoir),</li><li>zero or more <code>state_modifiers</code> applied to the reservoir state, and</li><li>a <a href="../layers/#ReservoirComputing.LinearReadout"><code>LinearReadout</code></a> mapping reservoir features to outputs.</li></ol><p><strong>Equations</strong></p><p>For input <code>\mathbf{x}(t) ∈ \mathbb{R}^{in\_dims}</code>, reservoir state <code>\mathbf{h}(t) ∈ \mathbb{R}^{res\_dims}</code>, and output <code>\mathbf{y}(t) ∈ \mathbb{R}^{out\_dims}</code>:</p><p class="math-container">\[\begin{aligned}
    \tilde{\mathbf{h}}(t) &amp;= \phi\!\left(\mathbf{W}_{in}\,\mathbf{x}(t) +
        \mathbf{W}_{res}\,\mathbf{h}(t-1) + \mathbf{b}\right) \\
    \mathbf{h}(t) &amp;= (1-\alpha)\,\mathbf{h}(t-1) + \alpha\,\tilde{\mathbf{h}}(t) \\
    \mathbf{z}(t) &amp;= \psi\!\left(\mathrm{Mods}\big(\mathbf{h}(t)\big)\right) \\
    \mathbf{y}(t) &amp;= \rho\!\left(\mathbf{W}_{out}\,\mathbf{z}(t) + \mathbf{b}_{out}\right)
\end{aligned}\]</p><p><strong>Arguments</strong></p><ul><li><code>in_dims</code>: Input dimension.</li><li><code>res_dims</code>: Reservoir (hidden state) dimension.</li><li><code>out_dims</code>: Output dimension.</li><li><code>activation</code>: Reservoir activation (for <a href="../layers/#ReservoirComputing.ESNCell"><code>ESNCell</code></a>). Default: <code>tanh</code>.</li></ul><p><strong>Keyword arguments</strong></p><p>Reservoir (passed to <a href="../layers/#ReservoirComputing.ESNCell"><code>ESNCell</code></a>):</p><ul><li><code>leak_coefficient</code>: Leak rate <code>α ∈ (0,1]</code>. Default: <code>1.0</code>.</li><li><code>init_reservoir</code>: Initializer for <code>W_res</code>. Default: <a href="../inits/rand_sparse/#rand_sparse"><code>rand_sparse</code></a>.</li><li><code>init_input</code>: Initializer for <code>W_in</code>. Default: <a href="../inits/scaled_rand/#scaled_rand"><code>scaled_rand</code></a>.</li><li><code>init_bias</code>: Initializer for reservoir bias (used iff <code>use_bias=true</code>). Default: <code>zeros32</code>.</li><li><code>init_state</code>: Initializer used when an external state is not provided. Default: <code>randn32</code>.</li><li><code>use_bias</code>: Whether the reservoir uses a bias term. Default: <code>false</code>.</li></ul><p>Composition:</p><ul><li><code>state_modifiers</code>: A layer or collection of layers applied to the reservoir state before the readout. Accepts a single layer, an <code>AbstractVector</code>, or a <code>Tuple</code>. Default: empty <code>()</code>.</li><li><code>readout_activation</code>: Activation for the linear readout. Default: <code>identity</code>.</li></ul><p><strong>Inputs</strong></p><ul><li><code>x :: AbstractArray (in_dims, batch)</code></li></ul><p><strong>Returns</strong></p><ul><li>Output <code>y :: (out_dims, batch)</code>.</li><li>Updated layer state (NamedTuple).</li></ul><p><strong>Parameters</strong></p><ul><li><code>reservoir</code> — parameters of the internal <a href="../layers/#ReservoirComputing.ESNCell"><code>ESNCell</code></a>, including:<ul><li><code>input_matrix :: (res_dims × in_dims)</code> — <code>W_in</code></li><li><code>reservoir_matrix :: (res_dims × res_dims)</code> — <code>W_res</code></li><li><code>bias :: (res_dims,)</code> — present only if <code>use_bias=true</code></li></ul></li><li><code>states_modifiers</code> — a <code>Tuple</code> with parameters for each modifier layer (may be empty).</li><li><code>readout</code> — parameters of <a href="../layers/#ReservoirComputing.LinearReadout"><code>LinearReadout</code></a>, typically:<ul><li><code>weight :: (out_dims × res_dims)</code> — <code>W_out</code></li><li><code>bias :: (out_dims,)</code> — <code>b_out</code> (if the readout uses bias)</li></ul></li></ul><blockquote><p>Exact field names for modifiers/readout follow their respective layer definitions.</p></blockquote><p><strong>States</strong></p><ul><li><code>reservoir</code> — states for the internal <a href="../layers/#ReservoirComputing.ESNCell"><code>ESNCell</code></a> (e.g. <code>rng</code> used to sample initial hidden states).</li><li><code>states_modifiers</code> — a <code>Tuple</code> with states for each modifier layer.</li><li><code>readout</code> — states for <a href="../layers/#ReservoirComputing.LinearReadout"><code>LinearReadout</code></a>.</li></ul></div><a class="docs-sourcelink" target="_blank" href="https://github.com/SciML/ReservoirComputing.jl/blob/e96dd3ed4b071df0b0fb3ab2151ec2d776284a13/src/models/esn.jl#L1-L87">source</a></section></details></article><article><details class="docstring" open="true"><summary id="ReservoirComputing.DeepESN"><a class="docstring-binding" href="#ReservoirComputing.DeepESN"><code>ReservoirComputing.DeepESN</code></a> — <span class="docstring-category">Type</span></summary><section><div><pre><code class="language-julia hljs">DeepESN(in_dims, res_dims, out_dims,
        activation=tanh; depth=2, leak_coefficient=1.0, init_reservoir=rand_sparse,
        init_input=scaled_rand, init_bias=zeros32, init_state=randn32,
        use_bias=false, state_modifiers=(), readout_activation=identity)</code></pre><p>Deep Echo State Network (DeepESN): a stack of stateful <a href="../layers/#ReservoirComputing.ESNCell"><code>ESNCell</code></a> layers (optionally with per-layer state modifiers) followed by a linear readout.</p><p><code>DeepESN</code> composes, for <code>L = length(res_dims)</code> layers:</p><ol><li>a sequence of stateful <a href="../layers/#ReservoirComputing.ESNCell"><code>ESNCell</code></a> with widths <code>res_dims[ℓ]</code>,</li><li>zero or more per-layer <code>state_modifiers[ℓ]</code> applied to the layer&#39;s state, and</li><li>a final <a href="../layers/#ReservoirComputing.LinearReadout"><code>LinearReadout</code></a> from the last layer&#39;s features to the output.</li></ol><p><strong>Equations</strong></p><p>For input <code>\mathbf{x}(t) ∈ \mathbb{R}^{in\_dims}</code>, per-layer reservoir states <code>\mathbf{h}^{(\ell)}(t) ∈ \mathbb{R}^{res\_dims[\ell]}</code> (<code>\ell = 1..L</code>), and output <code>\mathbf{y}(t) ∈ \mathbb{R}^{out\_dims}</code>:</p><p>```math \begin{aligned}     \tilde{\mathbf{h}}^{(1)}(t) &amp;= \phi<em>1!\left(         \mathbf{W}^{(1)}</em>{in}\,\mathbf{x}(t) + \mathbf{W}^{(1)}<em>{res}\,\mathbf{h}^{(1)}(t-1)         + \mathbf{b}^{(1)}\right) \
    \mathbf{h}^{(1)}(t) &amp;= (1-\alpha</em>1)\,\mathbf{h}^{(1)}(t-1) + \alpha<em>1\,\tilde{\mathbf{h}}^{(1)}(t) \
    \mathbf{u}^{(1)}(t) &amp;= \mathrm{Mods}</em>1!\big(\mathbf{h}^{(1)}(t)\big) \
    \tilde{\mathbf{h}}^{(\ell)}(t) &amp;= \phi<em>\ell!\left(         \mathbf{W}^{(\ell)}</em>{in}\,\mathbf{u}^{(\ell-1)}(t) +         \mathbf{W}^{(\ell)}<em>{res}\,\mathbf{h}^{(\ell)}(t-1) + \mathbf{b}^{(\ell)}\right),         \quad \ell=2..L \
    \mathbf{h}^{(\ell)}(t) &amp;= (1-\alpha</em>\ell)\,\mathbf{h}^{(\ell)}(t-1) + \alpha<em>\ell\,\tilde{\mathbf{h}}^{(\ell)}(t),         \quad \ell=2..L \
    \mathbf{u}^{(\ell)}(t) &amp;= \mathrm{Mods}</em>\ell!\big(\mathbf{h}^{(\ell)}(t)\big), \quad \ell=2..L \
    \mathbf{y}(t) &amp;= \rho!\left(\mathbf{W}<em>{out}\,\mathbf{u}^{(L)}(t) + \mathbf{b}</em>{out}\right) \end{aligned}</p><p><strong>Where</strong></p><ul><li><p><code>\mathbf{x}(t) ∈ ℝ^{in_dims × batch}</code> — input at time <code>t</code>.</p></li><li><p><code>\mathbf{h}^{(\ell)}(t) ∈ ℝ^{res_dims[ℓ] × batch}</code> — hidden state of layer <code>ℓ</code>.</p></li><li><p><code>\tilde{\mathbf{h}}^{(\ell)}(t)</code> — candidate state before leaky mixing.</p></li><li><p><code>\mathbf{u}^{(\ell)}(t)</code> — features after applying the <code>ℓ</code>-th <code>state_modifiers</code> (identity if none).</p></li><li><p><code>\mathbf{y}(t) ∈ ℝ^{out_dims × batch}</code> — network output.</p></li><li><p><code>\mathbf{W}^{(\ell)}_{in} ∈ ℝ^{res_dims[ℓ] × in\_size[ℓ]}</code> — input matrix at layer <code>ℓ</code> (<code>in_size[1]=in_dims</code>, <code>in_size[ℓ]=res_dims[ℓ-1]</code> for <code>ℓ&gt;1</code>).</p></li><li><p><code>\mathbf{W}^{(\ell)}_{res} ∈ ℝ^{res_dims[ℓ] × res_dims[ℓ]}</code> — reservoir matrix at layer <code>ℓ</code>.</p></li><li><p><code>\mathbf{b}^{(\ell)} ∈ ℝ^{res_dims[ℓ] × 1}</code> — reservoir bias (broadcast over batch), present iff <code>use_bias[ℓ]=true</code>.</p></li><li><p><code>\mathbf{W}_{out} ∈ ℝ^{out_dims × res_dims[L]}</code> — readout matrix.</p></li><li><p><code>\mathbf{b}_{out} ∈ ℝ^{out_dims × 1}</code> — readout bias (if used by the readout).</p></li><li><p><code>\phi_\ell</code> — activation of layer <code>ℓ</code> (<code>activation[ℓ]</code>, default <code>tanh</code>).</p></li><li><p><code>\alpha_\ell ∈ (0,1]</code> — leak coefficient of layer <code>ℓ</code> (<code>leak_coefficient[ℓ]</code>).</p></li><li><p><code>\mathrm{Mods}_\ell(·)</code> — composition of modifiers for layer <code>ℓ</code> (may be empty).</p></li><li><p><code>\rho</code> — readout activation (<code>readout_activation</code>, default <code>identity</code>).</p></li></ul><p><strong>Arguments</strong></p><ul><li><code>in_dims</code>: Input dimension.</li><li><code>res_dims</code>: Vector of reservoir (hidden) dimensions per layer; its length sets the depth <code>L</code>.</li><li><code>out_dims</code>: Output dimension.</li><li><code>activation</code>: Reservoir activation(s). Either a single function (broadcast to all layers) or a vector/tuple of length <code>L</code>. Default: <code>tanh</code>.</li></ul><p><strong>Keyword arguments</strong></p><p>Per-layer reservoir options (passed to each <a href="../layers/#ReservoirComputing.ESNCell"><code>ESNCell</code></a>):</p><ul><li><code>leak_coefficient</code>: Leak rate(s) <code>α_ℓ ∈ (0,1]</code>. Scalar or length-<code>L</code> collection. Default: <code>1.0</code>.</li><li><code>init_reservoir</code>: Initializer(s) for <code>W_res^{(ℓ)}</code>. Scalar or length-<code>L</code>. Default: <a href="../inits/rand_sparse/#rand_sparse"><code>rand_sparse</code></a>.</li><li><code>init_input</code>: Initializer(s) for <code>W_in^{(ℓ)}</code>. Scalar or length-<code>L</code>. Default: <a href="../inits/scaled_rand/#scaled_rand"><code>scaled_rand</code></a>.</li><li><code>init_bias</code>: Initializer(s) for reservoir bias (used iff <code>use_bias[ℓ]=true</code>). Scalar or length-<code>L</code>. Default: <code>zeros32</code>.</li><li><code>init_state</code>: Initializer(s) used when an external state is not provided. Scalar or length-<code>L</code>. Default: <code>randn32</code>.</li><li><code>use_bias</code>: Whether each reservoir uses a bias term. Boolean scalar or length-<code>L</code>. Default: <code>false</code>.</li><li><code>depth</code>: Depth of the DeepESN. If the reservoir size is given as a number instead of a vector, this parameter controls the depth of the model. Default is 2.</li></ul><p>Composition:</p><ul><li><code>state_modifiers</code>: Per-layer modifier(s) applied to each layer’s state before it feeds into the next layer (and the readout for the last layer). Accepts <code>nothing</code>, a single layer, a vector/tuple of length <code>L</code>, or per-layer collections. Defaults to no modifiers.</li><li><code>readout_activation</code>: Activation for the final linear readout. Default: <code>identity</code>.</li></ul><p><strong>Inputs</strong></p><ul><li><code>x :: AbstractArray (in_dims, batch)</code></li></ul><p><strong>Returns</strong></p><ul><li>Output <code>y :: (out_dims, batch)</code>.</li><li>Updated layer state (NamedTuple) containing states for all cells, modifiers, and readout.</li></ul><p><strong>Parameters</strong></p><ul><li><code>cells :: NTuple{L,NamedTuple}</code> — parameters for each <a href="../layers/#ReservoirComputing.ESNCell"><code>ESNCell</code></a>, including:<ul><li><code>input_matrix :: (res_dims[ℓ] × in_size[ℓ])</code> — <code>W_in^{(ℓ)}</code></li><li><code>reservoir_matrix :: (res_dims[ℓ] × res_dims[ℓ])</code> — <code>W_res^{(ℓ)}</code></li><li><code>bias :: (res_dims[ℓ],)</code> — present only if <code>use_bias[ℓ]=true</code></li></ul></li><li><code>states_modifiers :: NTuple{L,Tuple}</code> — per-layer tuples of modifier parameters (empty tuples if none).</li><li><code>readout</code> — parameters of <a href="../layers/#ReservoirComputing.LinearReadout"><code>LinearReadout</code></a>, typically:<ul><li><code>weight :: (out_dims × res_dims[L])</code> — <code>W_out</code></li><li><code>bias :: (out_dims,)</code> — <code>b_out</code> (if the readout uses bias)</li></ul></li></ul><blockquote><p>Exact field names for modifiers/readout follow their respective layer definitions.</p></blockquote><p><strong>States</strong></p><ul><li><code>cells :: NTuple{L,NamedTuple}</code> — states for each <a href="../layers/#ReservoirComputing.ESNCell"><code>ESNCell</code></a>.</li><li><code>states_modifiers :: NTuple{L,Tuple}</code> — per-layer tuples of modifier states.</li><li><code>readout</code> — states for <a href="../layers/#ReservoirComputing.LinearReadout"><code>LinearReadout</code></a>.</li></ul></div><a class="docs-sourcelink" target="_blank" href="https://github.com/SciML/ReservoirComputing.jl/blob/e96dd3ed4b071df0b0fb3ab2151ec2d776284a13/src/models/esn_deep.jl#L1-L116">source</a></section></details></article><article><details class="docstring" open="true"><summary id="ReservoirComputing.HybridESN"><a class="docstring-binding" href="#ReservoirComputing.HybridESN"><code>ReservoirComputing.HybridESN</code></a> — <span class="docstring-category">Type</span></summary><section><div><pre><code class="language-julia hljs">HybridESN(km, km_dims, in_dims, res_dims, out_dims, [activation];
    state_modifiers=(), readout_activation=identity,
    include_collect=true, kwargs...)</code></pre><p>Hybrid Echo State Network (HybridESN): an Echo State Network augmented with a knowledge model whose outputs are concatenated to the ESN’s input and used throughout the reservoir and readout computations.</p><p><code>HybridESN</code> composes:</p><ol><li>a knowledge model <code>km</code> producing auxiliary features from the input,</li><li>a stateful <a href="../layers/#ReservoirComputing.ESNCell"><code>ESNCell</code></a> that receives the concatenated input <code>[km(x(t)); x(t)]</code>,</li><li>zero or more <code>state_modifiers</code> applied to the reservoir state, and</li><li>a <a href="../layers/#ReservoirComputing.LinearReadout"><code>LinearReadout</code></a> mapping the combined features <code>[km(x(t)); h*(t)]</code> to the output.</li></ol><p><strong>Arguments</strong></p><ul><li><code>km</code>: Knowledge model applied to the input (e.g. a physical model, neural   submodule, or differentiable function). May be a <code>WrappedFunction</code> or any   callable layer.</li><li><code>km_dims</code>: Output dimension of the knowledge model <code>km</code>.</li><li><code>in_dims</code>: Input dimension.</li><li><code>res_dims</code>: Reservoir (hidden state) dimension.</li><li><code>out_dims</code>: Output dimension.</li><li><code>activation</code>: Reservoir activation (for <a href="../layers/#ReservoirComputing.ESNCell"><code>ESNCell</code></a>). Default: <code>tanh</code>.</li></ul><p><strong>Keyword arguments</strong></p><ul><li><code>leak_coefficient</code>: Leak rate <code>α ∈ (0,1]</code>. Default: <code>1.0</code>.</li><li><code>init_reservoir</code>: Initializer for <code>W_res</code>. Default: <a href="../inits/rand_sparse/#rand_sparse"><code>rand_sparse</code></a>.</li><li><code>init_input</code>: Initializer for <code>W_in</code>. Default: <a href="../inits/scaled_rand/#scaled_rand"><code>scaled_rand</code></a>.</li><li><code>init_bias</code>: Initializer for reservoir bias (used if <code>use_bias=true</code>).   Default: <code>zeros32</code>.</li><li><code>init_state</code>: Initializer used when an external state is not provided.   Default: <code>randn32</code>.</li><li><code>use_bias</code>: Whether the reservoir uses a bias term. Default: <code>false</code>.</li><li><code>state_modifiers</code>: A layer or collection of layers applied to the reservoir   state before the readout. Accepts a single layer, an <code>AbstractVector</code>, or a   <code>Tuple</code>. Default: empty <code>()</code>.</li><li><code>readout_activation</code>: Activation for the linear readout. Default: <code>identity</code>.</li><li><code>include_collect</code>: Whether the readout should include collection mode.   Default: <code>true</code>.</li></ul><p><strong>Inputs</strong></p><ul><li><code>x :: AbstractArray (in_dims, batch)</code></li></ul><p><strong>Returns</strong></p><ul><li>Output <code>y :: (out_dims, batch)</code>.</li><li>Updated layer state (NamedTuple).</li></ul><p><strong>Parameters</strong></p><ul><li><code>knowledge_model</code> — parameters of the knowledge model <code>km</code>.</li><li><code>cell</code> — parameters of the internal <a href="../layers/#ReservoirComputing.ESNCell"><code>ESNCell</code></a>, including:<ul><li><code>input_matrix :: (res_dims × (in_dims + km_dims))</code> — <code>W_in</code></li><li><code>reservoir_matrix :: (res_dims × res_dims)</code> — <code>W_res</code></li><li><code>bias :: (res_dims,)</code> — present only if <code>use_bias=true</code></li></ul></li><li><code>states_modifiers</code> — a <code>Tuple</code> with parameters for each modifier layer (may be empty).</li><li><code>readout</code> — parameters of <a href="../layers/#ReservoirComputing.LinearReadout"><code>LinearReadout</code></a>, typically:<ul><li><code>weight :: (out_dims × (res_dims + km_dims))</code> — <code>W_out</code></li><li><code>bias :: (out_dims,)</code> — <code>b_out</code> (if the readout uses bias)</li></ul></li></ul><blockquote><p>Exact field names for modifiers/readout follow their respective layer definitions.</p></blockquote><p><strong>States</strong></p><p>Created by <code>initialstates(rng, hesn)</code>:</p><ul><li><code>knowledge_model</code> — states for the internal knowledge model.</li><li><code>cell</code> — states for the internal <a href="../layers/#ReservoirComputing.ESNCell"><code>ESNCell</code></a>.</li><li><code>states_modifiers</code> — a <code>Tuple</code> with states for each modifier layer.</li><li><code>readout</code> — states for <a href="../layers/#ReservoirComputing.LinearReadout"><code>LinearReadout</code></a>.</li></ul></div><a class="docs-sourcelink" target="_blank" href="https://github.com/SciML/ReservoirComputing.jl/blob/e96dd3ed4b071df0b0fb3ab2151ec2d776284a13/src/models/esn_hybrid.jl#L2-L79">source</a></section></details></article><h3 id="Utilities"><a class="docs-heading-anchor" href="#Utilities">Utilities</a><a id="Utilities-1"></a><a class="docs-heading-anchor-permalink" href="#Utilities" title="Permalink"></a></h3><article><details class="docstring" open="true"><summary id="ReservoirComputing.resetcarry!"><a class="docstring-binding" href="#ReservoirComputing.resetcarry!"><code>ReservoirComputing.resetcarry!</code></a> — <span class="docstring-category">Function</span></summary><section><div><pre><code class="language-julia hljs">resetcarry!(rng, rc::ReservoirComputer, st; init_carry=nothing)
resetcarry!(rng, rc::ReservoirComputer, ps, st; init_carry=nothing)</code></pre><p>Reset (or set) the hidden-state carry of a model in the echo state network family.</p><p>If an existing carry is present in <code>st.cell.carry</code>, its leading dimension is used to infer the state size. Otherwise the reservoir output size is taken from <code>rc.reservoir.cell.out_dims</code>. When <code>init_carry=nothing</code>, the carry is cleared; the initializer from the struct construction will then be used. When a function is provided, it is called to create a new initial hidden state.</p><p><strong>Arguments</strong></p><ul><li><code>rng</code>: Random number generator (used if a new carry is sampled/created).</li><li><code>rc</code>: A reservoir computing network model.</li><li><code>st</code>: Current model states.</li><li><code>ps</code>: Optional model parameters. Returned unchanged.</li></ul><p><strong>Keyword arguments</strong></p><ul><li><code>init_carry</code>: Controls the initialization of the new carry.<ul><li><code>nothing</code> (default): remove/clear the carry (forces the cell to reinitialize from its own <code>init_state</code> on next use).</li><li><code>f</code>: a function following standard from <a href="https://lux.csail.mit.edu/stable/api/Building_Blocks/WeightInitializers">WeightInitializers.jl</a></li></ul></li></ul><p><strong>Returns</strong></p><ul><li><code>resetcarry!(rng, rc, st; ...) -&gt; st′</code>: Updated states with <code>st′.cell.carry</code> set to <code>nothing</code> or <code>(h0,)</code>.</li><li><code>resetcarry!(rng, rc, ps, st; ...) -&gt; (ps, st′)</code>: Same as above, but also returns the unchanged <code>ps</code> for convenience.</li></ul></div><a class="docs-sourcelink" target="_blank" href="https://github.com/SciML/ReservoirComputing.jl/blob/e96dd3ed4b071df0b0fb3ab2151ec2d776284a13/src/reservoircomputer.jl#L100-L134">source</a></section></details></article><h2 id="Reservoir-Computing-with-Cellular-Automata"><a class="docs-heading-anchor" href="#Reservoir-Computing-with-Cellular-Automata">Reservoir Computing with Cellular Automata</a><a id="Reservoir-Computing-with-Cellular-Automata-1"></a><a class="docs-heading-anchor-permalink" href="#Reservoir-Computing-with-Cellular-Automata" title="Permalink"></a></h2><article><details class="docstring" open="true"><summary id="ReservoirComputing.RECA"><a class="docstring-binding" href="#ReservoirComputing.RECA"><code>ReservoirComputing.RECA</code></a> — <span class="docstring-category">Function</span></summary><section><div><pre><code class="language-julia hljs">RECA(in_dims, out_dims, automaton;
    input_encoding=RandomMapping(),
    generations=8, state_modifiers=(),
    readout_activation=identity)</code></pre><p>Construct a cellular–automata reservoir model.</p><p>At each time step the input vector is randomly embedded into a Cellular Automaton (CA) lattice, the CA is evolved for <code>generations</code> steps, and the flattened evolution (excluding the initial row) is used as the reservoir state. A linear <a href="../layers/#ReservoirComputing.LinearReadout"><code>LinearReadout</code></a> maps these features to <code>out_dims</code>.</p><div class="admonition is-info" id="Note-1e88af8f9ecaf524"><header class="admonition-header">Note<a class="admonition-anchor" href="#Note-1e88af8f9ecaf524" title="Permalink"></a></header><div class="admonition-body"><p>This constructor is only available when the <code>CellularAutomata.jl</code> package is loaded.</p></div></div><p><strong>Arguments</strong></p><ul><li><code>in_dims</code>: Number of input features (rows of training data).</li><li><code>out_dims</code>: Number of output features (rows of target data).</li><li><code>automaton</code>: A CA rule/object from <code>CellularAutomata.jl</code> (e.g. <code>DCA(90)</code>, <code>DCA(30)</code>, …).</li></ul><p><strong>Keyword Arguments</strong></p><ul><li><code>input_encoding</code>: Random embedding spec with fields <code>permutations</code> and <code>expansion_size</code>. Default is <code>RandomMapping()</code>.</li><li><code>generations</code>: Number of CA generations to evolve per time step. Default is 8.</li><li><code>state_modifiers</code>: Optional tuple/vector of additional layers applied after the CA cell and before the readout (e.g., <code>NLAT2()</code>, <code>Pad(1.0)</code>, custom transforms, etc.). Functions are wrapped automatically. Default is none.</li><li><code>readout_activation</code>: Activation applied by the readout Default is <code>identity</code>.</li></ul></div><a class="docs-sourcelink" target="_blank" href="https://github.com/SciML/ReservoirComputing.jl/blob/e96dd3ed4b071df0b0fb3ab2151ec2d776284a13/src/extensions/reca.jl#L148-L185">source</a></section></details></article><p>The input encodings are the equivalent of the input matrices of the ESNs. These are the available encodings:</p><article><details class="docstring" open="true"><summary id="ReservoirComputing.RandomMapping"><a class="docstring-binding" href="#ReservoirComputing.RandomMapping"><code>ReservoirComputing.RandomMapping</code></a> — <span class="docstring-category">Type</span></summary><section><div><pre><code class="language-julia hljs">RandomMapping(permutations, expansion_size)
RandomMapping(permutations; expansion_size=40)
RandomMapping(;permutations=8, expansion_size=40)</code></pre><p>Specify the <strong>random input embedding</strong> used by the Cellular Automata reservoir. Each time step, the input vector of length <code>in_dims</code> is randomly placed into a larger 1D lattice of length <code>expansion_size</code>, and this is repeated for <code>permutations</code> independent lattices (blocks). The concatenation of these blocks forms the CA initial condition of length: <code>ca_size = expansion_size * permutations</code>. The detail of this implementation can be found in (<a href="../../references/#Nichele2017">Nichele and Molund, 2017</a>).</p><p><strong>Arguments</strong></p><ul><li><code>permutations</code>: number of independent random maps (blocks). Larger values increase feature diversity and <code>ca_size</code> proportionally.</li><li><code>expansion_size</code>: width of each block (the size of a single CA lattice). Larger values increase the spatial resolution and both <code>ca_size</code> and <code>states_size</code>.</li></ul><p><strong>Usage</strong></p><p>This is a <strong>configuration object</strong>; it does not perform the mapping by itself. Create the concrete tables with <code>create_encoding</code> and pass them to <a href="../layers/#ReservoirComputing.RECACell"><code>RECACell</code></a>:</p><pre><code class="language-julia hljs">using ReservoirComputing, CellularAutomata, Random

in_dims = 4
generations = 8
mapping = RandomMapping(permutations = 8, expansion_size = 40)

enc = ReservoirComputing.create_encoding(mapping, in_dims, generations)  # → RandomMaps
cell = RECACell(DCA(90), enc)

rc = ReservoirChain(
    StatefulLayer(cell),
    LinearReadout(enc.states_size =&gt; in_dims; include_collect = true)
)</code></pre><p>Or let <a href="#ReservoirComputing.RECA"><code>RECA</code></a> do this for you:</p><pre><code class="language-julia hljs">rc = RECA(in_dims = 4, out_dims = 4, DCA(90);
    input_encoding = RandomMapping(permutations = 8, expansion_size = 40),
    generations = 8)</code></pre></div><a class="docs-sourcelink" target="_blank" href="https://github.com/SciML/ReservoirComputing.jl/blob/e96dd3ed4b071df0b0fb3ab2151ec2d776284a13/src/extensions/reca.jl#L4-L53">source</a></section></details></article></article><nav class="docs-footer"><a class="docs-footer-prevpage" href="../layers/">« Layers</a><a class="docs-footer-nextpage" href="../utils/">Utilities »</a><div class="flexbox-break"></div><p class="footer-message">Powered by <a href="https://github.com/JuliaDocs/Documenter.jl">Documenter.jl</a> and the <a href="https://julialang.org/">Julia Programming Language</a>.</p></nav></div><div class="modal" id="documenter-settings"><div class="modal-background"></div><div class="modal-card"><header class="modal-card-head"><p class="modal-card-title">Settings</p><button class="delete"></button></header><section class="modal-card-body"><p><label class="label">Theme</label><div class="select"><select id="documenter-themepicker"><option value="auto">Automatic (OS)</option><option value="documenter-light">documenter-light</option><option value="documenter-dark">documenter-dark</option><option value="catppuccin-latte">catppuccin-latte</option><option value="catppuccin-frappe">catppuccin-frappe</option><option value="catppuccin-macchiato">catppuccin-macchiato</option><option value="catppuccin-mocha">catppuccin-mocha</option></select></div></p><hr/><p>This document was generated with <a href="https://github.com/JuliaDocs/Documenter.jl">Documenter.jl</a> version 1.16.1 on <span class="colophon-date" title="Saturday 29 November 2025 15:46">Saturday 29 November 2025</span>. Using Julia version 1.12.2.</p></section><footer class="modal-card-foot"></footer></div></div></div></body></html>
